{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "N7eHI1Wkd-t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variabili Globali\n",
        "VERSION = \"v2\"\n",
        "WINDOW_SIZE = 60\n",
        "STRIDE = 1\n",
        "\n",
        "# Iperparametri del modello BiLSTM+Attention e di addestramento\n",
        "EMBEDDING_DIM = 16\n",
        "LSTM_HIDDEN_DIM_BILSTM = 64     # Dimensione nascosta per OGNI DIREZIONE del BiLSTM. L'output combinato sarà HIDDEN_DIM * 2\n",
        "LSTM_NUM_LAYERS_BILSTM = 1      # Numero di layer BiLSTM. Se > 1, il dropout specificato in nn.LSTM si attiva.\n",
        "OUTPUT_DIM = 1                  # Output binario (un logit)\n",
        "DROPOUT_RATE = 0.5              # Dropout rate\n",
        "USE_BATCH_NORM_EMB = True       # Applica BatchNorm dopo la concatenazione iniziale di embedding e feature continue.\n",
        "USE_BATCH_NORM_ATTN_OUT = True  # Applica BatchNorm dopo che il vettore di contesto è stato calcolato dall'attention.\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 30\n",
        "PATIENCE_EARLY_STOPPING = 2\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilizzo del dispositivo: {DEVICE}\")"
      ],
      "metadata": {
        "id": "XKBP531OehgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a638c5cd-00f4-4789-acec-f120363b4c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilizzo del dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montaggio Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Percorsi\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV'\n",
        "sequences_path = f'{base_path}/Sequences'\n",
        "embeddings_path = f'{base_path}/Embeddings'\n",
        "models_path = f'{base_path}/Models'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM_HWv_aQrHe",
        "outputId": "b0cbc0f9-3e85-4a2a-d1ec-e7c2a6e00f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorsi ai file .npy salvati\n",
        "sequences_folder_name = f\"sequences_{VERSION}_W{WINDOW_SIZE}_S{STRIDE}\"\n",
        "user_split_strategy_folder_name = f\"user_split_W{WINDOW_SIZE}_S{STRIDE}\"\n",
        "split_data_dir = f'{sequences_path}/{sequences_folder_name}/{user_split_strategy_folder_name}'\n",
        "\n",
        "X_train_path = f'{split_data_dir}/X_train_normal_only.npy'\n",
        "y_train_path = f'{split_data_dir}/y_train_normal_only.npy'\n",
        "X_val_path = f'{split_data_dir}/X_val_user_split.npy'\n",
        "y_val_path = f'{split_data_dir}/y_val_user_split.npy'\n",
        "X_test_path = f'{split_data_dir}/X_test_user_split.npy'\n",
        "y_test_path = f'{split_data_dir}/y_test_user_split.npy'\n",
        "\n",
        "# Caricamento dei dati di training, validation e test\n",
        "print(f\"Caricamento X_train da: {X_train_path}\")\n",
        "X_train_np = np.load(X_train_path)\n",
        "print(f\"Caricamento y_train da: {y_train_path}\")\n",
        "y_train_np = np.load(y_train_path)\n",
        "\n",
        "print(f\"Caricamento X_val da: {X_val_path}\")\n",
        "X_val_np = np.load(X_val_path)\n",
        "print(f\"Caricamento y_val da: {y_val_path}\")\n",
        "y_val_np = np.load(y_val_path)\n",
        "\n",
        "print(f\"Caricamento X_test da: {X_test_path}\")\n",
        "X_test_np = np.load(X_test_path)\n",
        "print(f\"Caricamento y_test da: {y_test_path}\")\n",
        "y_test_np = np.load(y_test_path)\n",
        "\n",
        "print(f\"\\nForme dei dati caricati:\")\n",
        "print(f\"X_train: {X_train_np.shape}, y_train: {y_train_np.shape}\")\n",
        "print(f\"X_val:   {X_val_np.shape},  y_val:   {y_val_np.shape}\")\n",
        "print(f\"X_test:  {X_test_np.shape}, y_test:  {y_test_np.shape}\")"
      ],
      "metadata": {
        "id": "oEAiDHrTevAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca33938-9652-485f-dbee-4b62b153c31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricamento X_train da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/X_train_normal_only.npy\n",
            "Caricamento y_train da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/y_train_normal_only.npy\n",
            "Caricamento X_val da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/X_val_user_split.npy\n",
            "Caricamento y_val da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/y_val_user_split.npy\n",
            "Caricamento X_test da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/X_test_user_split.npy\n",
            "Caricamento y_test da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Sequences/sequences_v2_W60_S1/user_split_W60_S1/y_test_user_split.npy\n",
            "\n",
            "Forme dei dati caricati:\n",
            "X_train: (153184, 60, 9), y_train: (153184,)\n",
            "X_val:   (37641, 60, 9),  y_val:   (37641,)\n",
            "X_test:  (39241, 60, 9), y_test:  (39241,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_data_path = f'{embeddings_path}/embedding_data_{VERSION}.json'\n",
        "with open(embedding_data_path, 'r') as f:\n",
        "    embedding_data_json = json.load(f)\n",
        "\n",
        "categorical_feature_names = [\n",
        "    'src_user', 'dst_user', 'src_comp', 'dst_comp',\n",
        "    'auth_type', 'logon_type', 'auth_orientation', 'status'\n",
        "]\n",
        "continuous_feature_names = ['time_scaled_per_user']\n",
        "\n",
        "num_categorical_features = len(categorical_feature_names)\n",
        "num_continuous_features = len(continuous_feature_names)\n",
        "\n",
        "print(f\"\\nConfigurazione Feature:\")\n",
        "print(f\"Nomi feature categoriche (per embedding e vocab_size): {categorical_feature_names} (Numero: {num_categorical_features})\")\n",
        "print(f\"Nomi feature continue: {continuous_feature_names} (Numero: {num_continuous_features})\")\n",
        "\n",
        "expected_total_features = num_categorical_features + num_continuous_features\n",
        "if X_train_np.shape[2] != expected_total_features:\n",
        "    print(f\"ERRORE CRITICO: Il numero totale di feature attese ({expected_total_features})\") # AI: Corretto.\n",
        "    print(f\"non corrisponde alla terza dimensione di X_train ({X_train_np.shape[2]})!\")\n",
        "    print(\"Verifica l'ordine e i nomi in 'categorical_feature_names' e 'continuous_feature_names'.\")\n",
        "else:\n",
        "    print(f\"OK: Numero totale di feature ({expected_total_features}) corrisponde a X_train.shape[2] ({X_train_np.shape[2]}).\")\n",
        "\n",
        "ordered_vocab_sizes = []\n",
        "for original_col_name in categorical_feature_names:\n",
        "    vocab_size_key = f'{original_col_name}_vocab_size'\n",
        "    if vocab_size_key in embedding_data_json:\n",
        "        ordered_vocab_sizes.append(embedding_data_json[vocab_size_key])\n",
        "    else:\n",
        "        vocab_size_key_alt = f'{original_col_name.replace(\"_encoded\", \"\")}_vocab_size'\n",
        "        if vocab_size_key_alt in embedding_data_json:\n",
        "             ordered_vocab_sizes.append(embedding_data_json[vocab_size_key_alt])\n",
        "        else:\n",
        "            raise ValueError(f\"Vocab size non trovata per {original_col_name} in {embedding_data_path} (chiavi provate: {vocab_size_key}, {vocab_size_key_alt})\")\n",
        "\n",
        "print(f\"Dimensioni dei vocabolari (nell'ordine delle feature categoriche): {ordered_vocab_sizes} (Numero: {len(ordered_vocab_sizes)})\")\n",
        "if len(ordered_vocab_sizes) != num_categorical_features:\n",
        "    print(f\"ERRORE CRITICO: Il numero di vocab_sizes ({len(ordered_vocab_sizes)}) non corrisponde al numero di feature categoriche ({num_categorical_features})!\")"
      ],
      "metadata": {
        "id": "1zhhyHUYe3rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b7fbdd-f522-4657-add4-a437d573f2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurazione Feature:\n",
            "Nomi feature categoriche (per embedding e vocab_size): ['src_user', 'dst_user', 'src_comp', 'dst_comp', 'auth_type', 'logon_type', 'auth_orientation', 'status'] (Numero: 8)\n",
            "Nomi feature continue: ['time_scaled_per_user'] (Numero: 1)\n",
            "OK: Numero totale di feature (9) corrisponde a X_train.shape[2] (9).\n",
            "Dimensioni dei vocabolari (nell'ordine delle feature categoriche): [27767, 29962, 13078, 11642, 6, 10, 7, 2] (Numero: 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim_times_directions # hidden_dim_times_directions è la dimensione delle feature dell'output dell'LSTM per ogni time step\n",
        "        ):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn_weights_layer = nn.Linear(hidden_dim_times_directions, 1, bias=False)\n",
        "\n",
        "    def forward(self, lstm_output):\n",
        "        # Applica il layer lineare e una funzione di attivazione (tanh) per ottenere gli \"energy scores\"\n",
        "        energy = torch.tanh(self.attn_weights_layer(lstm_output)) # [batch_size, seq_len, 1]\n",
        "        # Rimuove l'ultima dimensione.\n",
        "        attention_raw_scores = energy.squeeze(2) # [batch_size, seq_len]\n",
        "        # Applica softmax lungo la dimensione della sequenza per normalizzare i punteggi in pesi di attention\n",
        "        return F.softmax(attention_raw_scores, dim=1)\n",
        "\n",
        "class BiLSTMAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_sizes,                  # Lista delle dimensioni dei vocabolari per le feature categoriche\n",
        "        embedding_dim,                # Dimensione degli embedding\n",
        "        num_continuous_features,      # Numero di feature continue\n",
        "        lstm_hidden_dim,              # Dimensione dello stato nascosto per ciascuna direzione del BiLSTM\n",
        "        lstm_num_layers,              # Numero di layer BiLSTM impilati\n",
        "        output_dim,                   # Dimensione dell'output finale (1 per classificazione binaria)\n",
        "        dropout_rate,                 # Tasso di dropout generale\n",
        "        use_batch_norm_emb=True,      # Flag per usare BatchNorm dopo gli embedding\n",
        "        use_batch_norm_attn_out=True  # Flag per usare BatchNorm dopo il vettore di contesto dell'attention\n",
        "        ):\n",
        "        super(BiLSTMAttention, self).__init__()\n",
        "\n",
        "        self.num_categorical_features = len(vocab_sizes)\n",
        "        self.num_continuous_features = num_continuous_features\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.lstm_num_layers = lstm_num_layers\n",
        "        self.use_batch_norm_emb = use_batch_norm_emb\n",
        "        self.use_batch_norm_attn_out = use_batch_norm_attn_out\n",
        "\n",
        "        # Layer di Embedding\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(num_embeddings=v_size, embedding_dim=embedding_dim) for v_size in vocab_sizes\n",
        "        ])\n",
        "\n",
        "        total_embedding_dim = self.num_categorical_features * self.embedding_dim\n",
        "        # Dimensione dell'input per il BiLSTM (embedding concatenati + feature continue)\n",
        "        bilstm_input_size = total_embedding_dim + self.num_continuous_features\n",
        "        print(f\"BiLSTM input size calcolata: {bilstm_input_size} (Embeddings: {total_embedding_dim} + Continue: {self.num_continuous_features})\")\n",
        "\n",
        "        if self.use_batch_norm_emb and bilstm_input_size > 0:\n",
        "            self.bn_emb_concat = nn.BatchNorm1d(bilstm_input_size)\n",
        "\n",
        "        # Layer BiLSTM\n",
        "        # bidirectional=True lo rende bidirezionale.\n",
        "        # dropout=dropout_rate applica dropout tra i layer BiLSTM se lstm_num_layers > 1\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=bilstm_input_size,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout_rate if lstm_num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Layer di Attention\n",
        "        # L'input per Attention è l'output del BiLSTM, che ha dimensione lstm_hidden_dim * 2 (per le due direzioni)\n",
        "        self.attention_layer = Attention(lstm_hidden_dim * 2)\n",
        "\n",
        "        # BatchNorm opzionale per l'output del meccanismo di attention\n",
        "        if self.use_batch_norm_attn_out:\n",
        "            self.bn_attention_out = nn.BatchNorm1d(lstm_hidden_dim * 2)\n",
        "\n",
        "        # Dropout prima del layer fully connected layer finale\n",
        "        self.fc_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Fully connected layer lineare per la classificazione finale\n",
        "        # Prende in input il vettore di contesto dall'attention\n",
        "        self.fc = nn.Linear(lstm_hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Processamento input: embedding delle categoriche e concatenazione con le continue\n",
        "        x_categorical = x[:, :, :self.num_categorical_features].long()\n",
        "        x_continuous = x[:, :, self.num_categorical_features:]\n",
        "        embedded_features_list = [self.embeddings[i](x_categorical[:, :, i]) for i in range(self.num_categorical_features)]\n",
        "        if self.num_categorical_features > 0:\n",
        "            current_features = torch.cat(embedded_features_list, dim=2)\n",
        "            if self.num_continuous_features > 0:\n",
        "                current_features = torch.cat((current_features, x_continuous.float()), dim=2)\n",
        "        elif self.num_continuous_features > 0:\n",
        "            current_features = x_continuous.float()\n",
        "        else:\n",
        "            raise ValueError(\"Il modello deve avere almeno una feature.\")\n",
        "\n",
        "        # BatchNorm sull'input processato per il BiLSTM\n",
        "        if hasattr(self, 'bn_emb_concat') and self.use_batch_norm_emb: # AI: Aggiunto check per self.use_batch_norm_emb\n",
        "            current_features = current_features.permute(0, 2, 1)\n",
        "            current_features = self.bn_emb_concat(current_features)\n",
        "            current_features = current_features.permute(0, 2, 1)\n",
        "\n",
        "        # Passaggio attraverso il BiLSTM\n",
        "        # lstm_output conterrà gli output concatenati delle direzioni forward e backward per ogni time step\n",
        "        lstm_output, _ = self.lstm(current_features) # [batch_size, seq_len, lstm_hidden_dim * 2]\n",
        "\n",
        "        # Calcolo dei pesi di Attention\n",
        "        attention_weights = self.attention_layer(lstm_output) # [batch_size, seq_len]\n",
        "\n",
        "        # Applica i pesi di attention agli output dell'LSTM per ottenere le feature \"pesate\"\n",
        "        weighted_features = lstm_output * attention_weights.unsqueeze(2)\n",
        "\n",
        "        # Somma pesata per ottenere il vettore di contesto\n",
        "        # Questo aggrega le informazioni dalla sequenza in un singolo vettore,\n",
        "        # dando più importanza ai time step con pesi di attention più alti.\n",
        "        context_vector = torch.sum(weighted_features, dim=1) # [batch_size, lstm_hidden_dim * 2]\n",
        "\n",
        "        # BatchNorm sul vettore di contesto\n",
        "        if hasattr(self, 'bn_attention_out') and self.use_batch_norm_attn_out:\n",
        "            context_vector = self.bn_attention_out(context_vector)\n",
        "\n",
        "        # Dropout sul vettore di contesto\n",
        "        context_vector_dropped_out = self.fc_dropout(context_vector)\n",
        "\n",
        "        # Layer lineare finale per ottenere i logits\n",
        "        output_logits = self.fc(context_vector_dropped_out)\n",
        "\n",
        "        # Restituisce i logits e, opzionalmente, i pesi di attention\n",
        "        return output_logits, attention_weights"
      ],
      "metadata": {
        "id": "Hy6ie7WThuKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Inizializzazione Modello BiLSTM+Attention\")\n",
        "\n",
        "model = BiLSTMAttention(\n",
        "    vocab_sizes=ordered_vocab_sizes,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    num_continuous_features=num_continuous_features,\n",
        "    lstm_hidden_dim=LSTM_HIDDEN_DIM_BILSTM,\n",
        "    lstm_num_layers=LSTM_NUM_LAYERS_BILSTM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    use_batch_norm_emb=USE_BATCH_NORM_EMB,\n",
        "    use_batch_norm_attn_out=USE_BATCH_NORM_ATTN_OUT\n",
        ")\n",
        "model.to(DEVICE)\n",
        "\n",
        "print(\"\\nModello BiLSTM+Attention istanziato:\")\n",
        "print(model)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "print(\"\\nLoss function e optimizer definiti.\")\n",
        "\n",
        "# Creazione DataLoaders\n",
        "print(\"\\nCreazione DataLoaders\")\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train_np).float()\n",
        "y_train_tensor = torch.from_numpy(y_train_np).float()\n",
        "\n",
        "X_val_tensor = torch.from_numpy(X_val_np).float()\n",
        "y_val_tensor = torch.from_numpy(y_val_np).float()\n",
        "\n",
        "X_test_tensor = torch.from_numpy(X_test_np).float()\n",
        "y_test_tensor = torch.from_numpy(y_test_np).float()\n",
        "\n",
        "# Creazione di TensorDataset, che incapsula tensori con la stessa prima dimensione\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Creazione dei DataLoader, che gestiscono il batching, lo shuffle e il caricamento parallelo dei dati\n",
        "# shuffle=True per il train_loader per ridurre la varianza del gradiente e migliorare la generalizzazione\n",
        "# drop_last=True per il train_loader per evitare batch di dimensioni diverse che potrebbero dare problemi con alcuni layer\n",
        "# shuffle=False per val_loader e test_loader perché l'ordine non deve cambiare per una valutazione consistente\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True) # Shuffle per il training\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Numero di batch in train_loader: {len(train_loader)}\")\n",
        "print(f\"Numero di batch in val_loader: {len(val_loader)}\")\n",
        "print(f\"Numero di batch in test_loader: {len(test_loader)}\")\n",
        "\n",
        "# Esempio di un batch dal train_loader\n",
        "# Utile per verificare le dimensioni dei tensori prodotti dal DataLoader\n",
        "if len(train_loader) > 0:\n",
        "    sample_x, sample_y = next(iter(train_loader))\n",
        "    print(f\"\\nForma di un batch di input X: {sample_x.shape}\")\n",
        "    print(f\"Forma di un batch di output y: {sample_y.shape}\")\n",
        "else:\n",
        "    print(\"\\nTrain loader è vuoto, non posso mostrare un batch di esempio.\")"
      ],
      "metadata": {
        "id": "Von02ltMHI6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e975cb-cd67-438f-db9e-a135a61171d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizializzazione Modello BiLSTM+Attention\n",
            "BiLSTM input size calcolata: 129 (Embeddings: 128 + Continue: 1)\n",
            "\n",
            "Modello BiLSTM+Attention istanziato:\n",
            "BiLSTMAttentionAnomalyDetector(\n",
            "  (embeddings): ModuleList(\n",
            "    (0): Embedding(27767, 16)\n",
            "    (1): Embedding(29962, 16)\n",
            "    (2): Embedding(13078, 16)\n",
            "    (3): Embedding(11642, 16)\n",
            "    (4): Embedding(6, 16)\n",
            "    (5): Embedding(10, 16)\n",
            "    (6): Embedding(7, 16)\n",
            "    (7): Embedding(2, 16)\n",
            "  )\n",
            "  (bn_emb_concat): BatchNorm1d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (lstm): LSTM(129, 64, batch_first=True, bidirectional=True)\n",
            "  (attention_layer): Attention(\n",
            "    (attn_weights_layer): Linear(in_features=128, out_features=1, bias=False)\n",
            "  )\n",
            "  (bn_attention_out): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Loss function e optimizer definiti.\n",
            "\n",
            "Creazione DataLoaders\n",
            "Numero di batch in train_loader: 2393\n",
            "Numero di batch in val_loader: 589\n",
            "Numero di batch in test_loader: 614\n",
            "\n",
            "Forma di un batch di input X: torch.Size([64, 60, 9])\n",
            "Forma di un batch di output y: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup per Early Stopping\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "best_model_weights_path = f\"{models_path}/bilstm_attention_best_model_weights.pt\"\n",
        "\n",
        "train_losses_log = []\n",
        "val_losses_log = []\n",
        "\n",
        "print(f\"\\nInizio training per {NUM_EPOCHS} epoche (con Early Stopping, patience={PATIENCE_EARLY_STOPPING}) ---\")\n",
        "\n",
        "# Ciclo di Training (la logica interna è la stessa del LSTM)\n",
        "for epoch in range(NUM_EPOCHS): # Mette il modello in modalità training\n",
        "    model.train()\n",
        "\n",
        "    train_loss_accum = 0\n",
        "\n",
        "    # Itera sui batch del training set\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Azzera i gradienti accumulati dal batch precedente\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: ottiene i logits dal modello\n",
        "        # Il secondo output (stato nascosto) dell'LSTM non è usato qui\n",
        "        outputs_logits, _ = model(inputs)\n",
        "\n",
        "        # Calcola la loss\n",
        "        # .squeeze() rimuove la dimensione superflua (es. da [64,1] a [64])\n",
        "        loss = criterion(outputs_logits.squeeze(), labels)\n",
        "\n",
        "        # Calcola i gradienti della loss rispetto ai parametri del modello (backpropagation)\n",
        "        loss.backward()\n",
        "\n",
        "        # Aggiorna i pesi del modello usando i gradienti calcolati\n",
        "        optimizer.step()\n",
        "\n",
        "      # Accumula la loss del batch\n",
        "        train_loss_accum += loss.item()\n",
        "\n",
        "    # Calcolo loss media di training per l'epoca\n",
        "    avg_train_loss = train_loss_accum / len(train_loader)\n",
        "\n",
        "    train_losses_log.append(avg_train_loss)\n",
        "\n",
        "    # VALIDATION LOOP\n",
        "    model.eval() # Metti il modello in modalità valutazione\n",
        "    val_loss_accum = 0\n",
        "\n",
        "    # Inizializza le liste per raccogliere etichette e predizioni dell'epoca corrente\n",
        "    epoch_all_val_labels = []\n",
        "    epoch_all_val_preds_0_5_thresh = [] # Predizioni basate su soglia 0.5 solo per logging per epoca\n",
        "\n",
        "    with torch.no_grad(): # Disabilita il calcolo dei gradienti durante la validazione\n",
        "        for inputs_val, labels_val_batch in val_loader: # AI: Rinominato per chiarezza\n",
        "            inputs_val, labels_val_gpu = inputs_val.to(DEVICE), labels_val_batch.to(DEVICE) # AI: labels_val_gpu per la loss\n",
        "\n",
        "            outputs_val_logits, _ = model(inputs_val) # AI: Ignora i pesi di attention per la loss\n",
        "\n",
        "            val_loss = criterion(outputs_val_logits.squeeze(), labels_val_gpu)\n",
        "            val_loss_accum += val_loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss_accum / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "    # Logica di Early Stopping\n",
        "    # Se la Val Loss attuale è migliore della migliore finora\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        # Salva i pesi del modello\n",
        "        torch.save(model.state_dict(), best_model_weights_path)\n",
        "        print(f\"  Miglioramento Val Loss: {best_val_loss:.6f}. Modello salvato in {best_model_weights_path}\")\n",
        "        # Resetta il contatore delle epoche senza miglioramento\n",
        "        epochs_no_improve = 0\n",
        "    else: #  Se la Val Loss non è migliorata\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"  Nessun miglioramento Val Loss per {epochs_no_improve} epoche.\")\n",
        "\n",
        "    # Se la Val Loss non migliora per 'patience' epoche consecutive\n",
        "    if epochs_no_improve >= PATIENCE_EARLY_STOPPING:\n",
        "        print(f\"Early stopping attivato dopo {epoch+1} epoche.\")\n",
        "        break # Interrompi il training\n",
        "print(\"\\nTraining completato.\")"
      ],
      "metadata": {
        "id": "Uzssj18bI5Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c824cc47-f33e-4e85-bc65-4f83da333d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inizio training per 30 epoche (con Early Stopping, patience=2) ---\n",
            "Epoch 1/30 | Train Loss: 0.376774 | Val Loss: 0.790486\n",
            "  Miglioramento Val Loss: 0.790486. Modello salvato in /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Models/bilstm_attention_best_model_weights.pt\n",
            "Epoch 2/30 | Train Loss: 0.039673 | Val Loss: 0.270853\n",
            "  Miglioramento Val Loss: 0.270853. Modello salvato in /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Models/bilstm_attention_best_model_weights.pt\n",
            "Epoch 3/30 | Train Loss: 0.006451 | Val Loss: 0.202801\n",
            "  Miglioramento Val Loss: 0.202801. Modello salvato in /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Models/bilstm_attention_best_model_weights.pt\n",
            "Epoch 4/30 | Train Loss: 0.001526 | Val Loss: 0.214547\n",
            "  Nessun miglioramento Val Loss per 1 epoche.\n",
            "Epoch 5/30 | Train Loss: 0.000524 | Val Loss: 0.255098\n",
            "  Nessun miglioramento Val Loss per 2 epoche.\n",
            "Early stopping attivato dopo 5 epoche.\n",
            "\n",
            "Training completato.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Caricamento del modello BiLSTM+Attention con la migliore Val Loss da: {best_model_weights_path} ---\")\n",
        "model_eval = BiLSTMAttention( # Ricrea la stessa architettura\n",
        "    vocab_sizes=ordered_vocab_sizes,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    num_continuous_features=num_continuous_features,\n",
        "    lstm_hidden_dim=LSTM_HIDDEN_DIM_BILSTM,\n",
        "    lstm_num_layers=LSTM_NUM_LAYERS_BILSTM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    use_batch_norm_emb=USE_BATCH_NORM_EMB,\n",
        "    use_batch_norm_attn_out=USE_BATCH_NORM_ATTN_OUT\n",
        ")\n",
        "model_eval.load_state_dict(torch.load(best_model_weights_path, map_location=DEVICE))\n",
        "model_eval.to(DEVICE)\n",
        "model_eval.eval()\n",
        "print(\"Modello migliore BiLSTM+Attention caricato e pronto per la valutazione.\")"
      ],
      "metadata": {
        "id": "IMUPYlDpJMxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161da799-7fc6-4ad0-c9c6-14de8b44d0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Caricamento del modello BiLSTM+Attention con la migliore Val Loss da: /content/drive/MyDrive/Colab Notebooks/Deep_Learning_2025_IV/Models/bilstm_attention_best_model_weights.pt ---\n",
            "BiLSTM input size calcolata: 129 (Embeddings: 128 + Continue: 1)\n",
            "Modello migliore BiLSTM+Attention caricato e pronto per la valutazione.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione get_predictions_and_labels\n",
        "# per l'output del BiLSTM+Attention, che restituisce logits e pesi di attention\n",
        "def get_predictions_and_labels_attention(model, data_loader, device_eval):\n",
        "    model.eval()\n",
        "    all_labels_eval = []\n",
        "    all_probs_eval = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs_eval, labels_eval in data_loader:\n",
        "            inputs_eval = inputs_eval.to(device_eval)\n",
        "            # Il modello BiLSTMAttention restituisce (logits, attention_weights)\n",
        "            outputs_logits_eval, attention_w_batch = model(inputs_eval) # Prende entrambi gli output\n",
        "\n",
        "            squeezed_logits = outputs_logits_eval.squeeze()\n",
        "            probs_for_batch = torch.sigmoid(squeezed_logits)\n",
        "\n",
        "            all_labels_eval.extend(labels_eval.cpu().numpy().tolist())\n",
        "            np_probs_for_batch = probs_for_batch.cpu().numpy()\n",
        "            if np_probs_for_batch.ndim == 0:\n",
        "                all_probs_eval.append(float(np_probs_for_batch))\n",
        "            else:\n",
        "                all_probs_eval.extend(np_probs_for_batch.tolist())\n",
        "\n",
        "    return np.array(all_labels_eval), np.array(all_probs_eval)\n",
        "\n",
        "print(\"Funzione get_predictions_and_labels_attention definita.\")"
      ],
      "metadata": {
        "id": "DqXdAbdKJl73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f2a435-4f1a-43d8-bda1-7457e7dbc0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funzione get_predictions_and_labels_attention definita.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ottieni predizioni una sola volta\n",
        "print(\"Ottenimento predizioni finali dal modello migliore (BiLSTM+Attention)...\")\n",
        "# Carica il modello migliore e ottiene le predizioni (probabilità)\n",
        "# e le etichette vere per il validation e test set\n",
        "val_labels_final, val_probs_final = get_predictions_and_labels_attention(model_eval, val_loader, DEVICE)\n",
        "test_labels_final, test_probs_final = get_predictions_and_labels_attention(model_eval, test_loader, DEVICE)\n",
        "print(\"Predizioni finali ottenute.\")\n",
        "\n",
        "# Visualizzazione della distribuzione delle probabilità (VALIDATION SET)\n",
        "# Questa sezione serve a capire come il modello distribuisce le probabilità\n",
        "# per le classi normali e anomale sul validation set. Serve una buona separazione\n",
        "print(\"\\nDistribuzione delle probabilità predette sul Validation Set (BiLSTM+Attention):\")\n",
        "val_probs_normal = val_probs_final[val_labels_final == 0]\n",
        "val_probs_anomalous = val_probs_final[val_labels_final == 1]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(val_probs_normal, bins=50, alpha=0.7, label=f'Normali (Validation) (n={len(val_probs_normal)})', color='blue', density=True)\n",
        "if len(val_probs_anomalous) > 0:\n",
        "    plt.hist(val_probs_anomalous, bins=50, alpha=0.7, label=f'Anomale (Validation) (n={len(val_probs_anomalous)})', color='red', density=True)\n",
        "else:\n",
        "    print(\"Nessuna anomalia nel validation set per plottare il suo istogramma.\")\n",
        "plt.title('Distribuzione Probabilità Predette (Validation Set) - BiLSTM+Attention')\n",
        "plt.xlabel('Probabilità Predetta di Anomalia')\n",
        "plt.ylabel('Densità')\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()\n",
        "\n",
        "# Stampa statistiche descrittive delle probabilità per le due classi\n",
        "print(f\"Statistiche val_probs_normal: N={len(val_probs_normal)}, Min={np.min(val_probs_normal):.2e}, Max={np.max(val_probs_normal):.2e}, Mean={np.mean(val_probs_normal):.2e}, Median={np.median(val_probs_normal):.2e}\")\n",
        "if len(val_probs_anomalous) > 0:\n",
        "    print(f\"Statistiche val_probs_anomalous: N={len(val_probs_anomalous)}, Min={np.min(val_probs_anomalous):.2e}, Max={np.max(val_probs_anomalous):.2e}, Mean={np.mean(val_probs_anomalous):.2e}, Median={np.median(val_probs_anomalous):.2e}\")\n",
        "\n",
        "# Determinazione della soglia ottimale con il metodo del percentile (VALIDATION SET)\n",
        "print(\"\\n--- Determinazione Soglia Ottimale con Metodo Percentile (su Validation Set) ---\")\n",
        "percentiles_to_try = [85, 90, 95, 97, 98, 99, 99.5, 99.9]\n",
        "best_f1_val_percentile = -1 # Inizializza a -1.0 per assicurare che qualsiasi F1 valido sia maggiore\n",
        "final_optimal_threshold = 0.5 # Soglia di default se non si trovano anomalie\n",
        "best_percentile_chosen = 0\n",
        "num_anomalies_val = np.sum(val_labels_final == 1)\n",
        "print(f\"Numero di anomalie effettive nel Validation Set: {num_anomalies_val}\")\n",
        "\n",
        "# Cerca la soglia percentile che massimizza l'F1-score sulla classe anomala\n",
        "if len(val_probs_final) > 0 and num_anomalies_val > 0:\n",
        "    for p_val in percentiles_to_try:\n",
        "        # Calcola la soglia per il percentile corrente\n",
        "        current_threshold = np.percentile(val_probs_final, p_val)\n",
        "        # Classifica in base alla soglia\n",
        "        val_preds_p = (val_probs_final >= current_threshold).astype(int)\n",
        "        precision_p = precision_score(val_labels_final, val_preds_p, pos_label=1, zero_division=0)\n",
        "        recall_p = recall_score(val_labels_final, val_preds_p, pos_label=1, zero_division=0)\n",
        "        f1_p = f1_score(val_labels_final, val_preds_p, pos_label=1, zero_division=0)\n",
        "        print(f\"  Percentile: {p_val:>5}% -> Soglia: {current_threshold:.2e} | P: {precision_p:.4f}, R: {recall_p:.4f}, F1: {f1_p:.4f}\")\n",
        "\n",
        "        # Ottimizza per F1-score\n",
        "        if f1_p > best_f1_val_percentile:\n",
        "            best_f1_val_percentile = f1_p\n",
        "            final_optimal_threshold = current_threshold\n",
        "            best_percentile_chosen = p_val\n",
        "    print(f\"\\nMiglior Soglia (Percentile) scelta: {final_optimal_threshold:.2e} (dal {best_percentile_chosen}° percentile, F1 su Val: {best_f1_val_percentile:.4f})\")\n",
        "elif num_anomalies_val == 0:\n",
        "    print(\"Nessuna anomalia nel validation set, non posso ottimizzare la soglia percentile in modo significativo. Uso default 0.5.\")\n",
        "else: # val_probs_final è vuoto\n",
        "    print(\"val_probs_final è vuoto, non posso calcolare la soglia. Uso default 0.5.\")\n",
        "\n",
        "# Determinazione Soglia con per ottimizzare la recall\n",
        "print(f\"\\nPerformance su Validation Set con Soglia Finale ({final_optimal_threshold:.2e})\")\n",
        "val_predicted_labels_final = (val_probs_final >= final_optimal_threshold).astype(int)\n",
        "print(classification_report(val_labels_final, val_predicted_labels_final, target_names=['Normale (0)', 'Anomalo (1)'], zero_division=0))\n",
        "cm_val = confusion_matrix(val_labels_final, val_predicted_labels_final)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred. Normale', 'Pred. Anomalo'], yticklabels=['Vero Normale', 'Vero Anomalo'])\n",
        "plt.title(f'Validation Set - CM (Soglia={final_optimal_threshold:.2e})')\n",
        "plt.xlabel('Etichetta Predetta'); plt.ylabel('Etichetta Vera'); plt.show()\n",
        "\n",
        "# Valutazione finale sul test set con la soglia scelta\n",
        "print(f\"\\n--- Performance Finale sul Test Set con Soglia ({final_optimal_threshold:.2e}) ---\")\n",
        "test_predicted_labels_final = (test_probs_final >= final_optimal_threshold).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report completo sul Test Set:\")\n",
        "print(classification_report(test_labels_final, test_predicted_labels_final, target_names=['Normale (0)', 'Anomalo (1)'], zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix sul Test Set:\")\n",
        "cm_test = confusion_matrix(test_labels_final, test_predicted_labels_final)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred. Normale', 'Pred. Anomalo'], yticklabels=['Vero Normale', 'Vero Anomalo'])\n",
        "plt.title(f'Test Set - CM (Soglia={final_optimal_threshold:.2e})')\n",
        "plt.xlabel('Etichetta Predetta'); plt.ylabel('Etichetta Vera'); plt.show()\n",
        "\n",
        "# Conteggio finale dei veri positivi sul test set\n",
        "num_anomalies_test = np.sum(test_labels_final == 1)\n",
        "true_positives_test = cm_test[1, 1] if num_anomalies_test > 0 and cm_test.shape == (2,2) else 0\n",
        "print(f\"Numero di anomalie effettive nel Test Set: {num_anomalies_test}\")\n",
        "if num_anomalies_test > 0:\n",
        "    print(f\"Anomalie correttamente identificate (TP) nel Test Set: {true_positives_test} su {num_anomalies_test}\")"
      ],
      "metadata": {
        "id": "T37hizvPddE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}